import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from kneed import KneeLocator
import os

# Configura√ß√£o para melhor visualiza√ß√£o dos gr√°ficos
plt.style.use('seaborn-v0_8-whitegrid')
sns.set(font_scale=1.2)
colors = sns.color_palette("viridis", 6)

# Fun√ß√£o para carregar e tratar os dados dos arquivos CSV
def load_data(years=[2017, 2018, 2019, 2020]):
    all_data = []
    
    for year in years:
        filename = f"{year}.csv"
        try:
            # Tentativa de leitura do arquivo CSV
            df = pd.read_csv(filename, na_values=['m'])
            df['Year'] = year  # Adicionar coluna para identificar o ano
            all_data.append(df)
            print(f"  ‚Ä¢ {filename}: ‚úÖ Carregado com sucesso")
        except FileNotFoundError:
            print(f"  ‚Ä¢ {filename}: ‚ùå Arquivo n√£o encontrado")
    
    if not all_data:
        print("‚ùå ERRO: Nenhum arquivo foi carregado.")
        return None
    
    # Combinando todos os DataFrames
    combined_data = pd.concat(all_data, ignore_index=True)
    print(f"\n‚úÖ Dataset combinado: {combined_data.shape[0]} empresas √ó {combined_data.shape[1]} vari√°veis")
    
    return combined_data

# Fun√ß√£o para pr√©-processamento dos dados
def preprocess_data(df):
    if df is None:
        return None, None
    
    # Exibindo informa√ß√µes sobre valores faltantes
    missing_values = df.isnull().sum().sum()
    print(f"  ‚Ä¢ Valores faltantes encontrados: {missing_values}")
    
    # Extraindo colunas categ√≥ricas e num√©ricas
    categorical_cols = ['Country', 'S', 'Year']
    numeric_cols = [col for col in df.columns if col.startswith('X')]
    
    # Verificando se todas as colunas num√©ricas est√£o presentes
    print(f"  ‚Ä¢ Indicadores econ√¥micos encontrados: {len(numeric_cols)}")
    
    # Criando um novo DataFrame contendo apenas as colunas relevantes
    data_processed = df[categorical_cols + numeric_cols].copy()
    
    # Lidando com valores faltantes nas colunas num√©ricas (substituir por m√©dia)
    for col in numeric_cols:
        data_processed[col] = data_processed[col].fillna(data_processed[col].mean())
    
    # Detec√ß√£o e tratamento de outliers
    print("\nüîç DETEC√á√ÉO E TRATAMENTO DE OUTLIERS:")
    
    # Criando c√≥pias das colunas num√©ricas para an√°lise
    X = data_processed[numeric_cols].copy()
    
    # Calculando Z-scores para cada coluna num√©rica
    z_scores = pd.DataFrame()
    for col in numeric_cols:
        z_scores[col] = (X[col] - X[col].mean()) / X[col].std()
    
    # Identificando outliers usando Z-score (|z| > 3)
    outliers_mask = (z_scores.abs() > 3).any(axis=1)
    outliers_count = outliers_mask.sum()
    print(f"  ‚Ä¢ Outliers identificados: {outliers_count} registros ({outliers_count/len(data_processed)*100:.1f}% do total)")
    
    if outliers_count > 0:
        # Mostrando distribui√ß√£o de outliers por pa√≠s
        outliers_by_country = data_processed.loc[outliers_mask, 'Country'].value_counts()
        print(f"\n  ‚Ä¢ Distribui√ß√£o de outliers por pa√≠s:")
        for country, count in outliers_by_country.items():
            print(f"      - {country}: {count} registros")
        
        # Mostrando distribui√ß√£o de outliers por setor
        sector_map = {
            1: 'Transporte', 
            2: 'Com√©rcio Atacadista', 
            3: 'Manufatura',
            4: 'Varejo', 
            5: 'Energia', 
            6: 'Constru√ß√£o Civil'
        }
        outliers_by_sector = data_processed.loc[outliers_mask, 'S'].value_counts()
        print(f"\n  ‚Ä¢ Distribui√ß√£o de outliers por setor:")
        for sector, count in outliers_by_sector.items():
            print(f"      - {sector_map[sector]}: {count} registros")
        
        # Removendo outliers
        print(f"\n  ‚Ä¢ Removendo outliers para melhorar qualidade do clustering...")
        data_processed = data_processed.loc[~outliers_mask]
        print(f"  ‚Ä¢ Dataset ap√≥s remo√ß√£o: {len(data_processed)} empresas √ó {len(data_processed.columns)} vari√°veis")
    else:
        print("  ‚Ä¢ N√£o foram encontrados outliers significativos.")
    
    # Contando valores √∫nicos nas vari√°veis categ√≥ricas
    print("\nAnalisando dados categ√≥ricos:")
    print(f"  ‚Ä¢ Pa√≠ses: {', '.join(data_processed['Country'].unique())}")
    
    sector_map = {
        1: 'Transporte', 
        2: 'Com√©rcio Atacadista', 
        3: 'Manufatura',
        4: 'Varejo', 
        5: 'Energia', 
        6: 'Constru√ß√£o Civil'
    }
    sectors = [f"{s} ({sector_map[s]})" for s in sorted(data_processed['S'].unique())]
    print(f"  ‚Ä¢ Setores: {', '.join(sectors)}")
    
    # Exibindo informa√ß√µes sobre o dataset processado
    print(f"\n‚úÖ Dataset processado e pronto para an√°lise!")
    
    # Retornando o dataset processado e as colunas num√©ricas
    return data_processed, numeric_cols

# Fun√ß√£o para determinar o n√∫mero ideal de clusters (m√©todo do cotovelo)
def find_optimal_clusters(data, numeric_cols, max_clusters=11):
    # Prepara√ß√£o dos dados para clustering
    X = data[numeric_cols].values
    
    # Padronizando os dados
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Calculando in√©rcia para diferentes valores de k
    print("\nCalculando in√©rcia para valores de k de 1 a 10...")
    inertia_values = []
    k_values = range(1, max_clusters)
    
    for k in k_values:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(X_scaled)
        inertia_values.append(kmeans.inertia_)
        print(f"  ‚Ä¢ k={k}: in√©rcia = {kmeans.inertia_:.2f}")
    
    # Plotando o gr√°fico do m√©todo do cotovelo
    plt.figure(figsize=(10, 6))
    plt.plot(k_values, inertia_values, 'o-', color='blue', linewidth=2, markersize=8)
    plt.xlabel('N√∫mero de Clusters (k)')
    plt.ylabel('In√©rcia')
    plt.title('M√©todo do Cotovelo para Determinar o N√∫mero Ideal de Clusters')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('elbow_method.png')
    plt.close()
    
    # Usando a biblioteca KneeLocator para encontrar o ponto √≥timo
    try:
        kneedle = KneeLocator(k_values, inertia_values, 
                           curve='convex', 
                           direction='decreasing')
        optimal_k = kneedle.elbow
        print(f"\n‚úÖ M√©todo do cotovelo identificou {optimal_k} como n√∫mero ideal de clusters")
    except:
        # Se ocorrer algum erro com o KneeLocator, definimos um valor padr√£o
        optimal_k = 4
        print(f"\n‚ö†Ô∏è Ocorreu um erro ao usar KneeLocator. Usando valor padr√£o: {optimal_k} clusters")
    
    return optimal_k, X_scaled

# Fun√ß√£o para realizar clustering e visualizar resultados
def perform_clustering(data, numeric_cols, n_clusters, X_scaled=None):
    if X_scaled is None:
        # Prepara√ß√£o dos dados para clustering (caso n√£o tenha sido feito antes)
        X = data[numeric_cols].values
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
    
    # Aplicando K-means com o n√∫mero ideal de clusters
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(X_scaled)
    
    # Adicionando os r√≥tulos de cluster ao DataFrame
    data['Cluster'] = cluster_labels
    
    # Executando PCA para visualiza√ß√£o em 2D
    pca = PCA(n_components=2)
    principal_components = pca.fit_transform(X_scaled)
    
    # Criando um DataFrame com os componentes principais
    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])
    pca_df['Cluster'] = cluster_labels
    pca_df['Country'] = data['Country'].values
    pca_df['Sector'] = data['S'].values
    pca_df['Year'] = data['Year'].values
    
    # Mapeando valores de setor para nomes descritivos
    sector_names = {
        1: 'Transporte',
        2: 'Com√©rcio Atacadista',
        3: 'Manufatura',
        4: 'Varejo',
        5: 'Energia',
        6: 'Constru√ß√£o Civil'
    }
    pca_df['Sector_Name'] = pca_df['Sector'].map(sector_names)
    
    # Visualiza√ß√£o dos clusters usando PCA
    plt.figure(figsize=(12, 8))
    for cluster in range(n_clusters):
        plt.scatter(
            pca_df[pca_df['Cluster'] == cluster]['PC1'], 
            pca_df[pca_df['Cluster'] == cluster]['PC2'], 
            s=50, 
            label=f'Cluster {cluster}'
        )
    
    plt.title(f'Visualiza√ß√£o dos {n_clusters} Clusters usando PCA')
    plt.xlabel('Componente Principal 1')
    plt.ylabel('Componente Principal 2')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('clusters_pca.png')
    plt.close()
    
    # Visualiza√ß√£o dos clusters por pa√≠s
    plt.figure(figsize=(12, 8))
    countries = pca_df['Country'].unique()
    for i, country in enumerate(countries):
        country_data = pca_df[pca_df['Country'] == country]
        plt.scatter(
            country_data['PC1'], 
            country_data['PC2'], 
            s=50,
            label=country
        )
    
    plt.title('Visualiza√ß√£o dos Dados por Pa√≠s (PCA)')
    plt.xlabel('Componente Principal 1')
    plt.ylabel('Componente Principal 2')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('clusters_by_country.png')
    plt.close()
    
    # Visualiza√ß√£o dos clusters por setor
    plt.figure(figsize=(12, 8))
    for i, (sector_id, sector_name) in enumerate(sector_names.items()):
        sector_data = pca_df[pca_df['Sector'] == sector_id]
        if len(sector_data) > 0:  # Verifica se existem dados para este setor
            plt.scatter(
                sector_data['PC1'], 
                sector_data['PC2'], 
                s=50,
                label=sector_name
            )
    
    plt.title('Visualiza√ß√£o dos Dados por Setor (PCA)')
    plt.xlabel('Componente Principal 1')
    plt.ylabel('Componente Principal 2')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('clusters_by_sector.png')
    plt.close()
    
    # An√°lise da distribui√ß√£o de pa√≠ses e setores por cluster
    print("\n" + "="*80)
    print("üîç AN√ÅLISE DA DISTRIBUI√á√ÉO DE PA√çSES E SETORES POR CLUSTER")
    print("="*80)
    
    # Mapeamento de setores para nomes descritivos
    sector_names = {
        1: 'Transporte',
        2: 'Com√©rcio Atacadista',
        3: 'Manufatura',
        4: 'Varejo',
        5: 'Energia',
        6: 'Constru√ß√£o Civil'
    }
    
    for i in range(n_clusters):
        cluster_data = data[data['Cluster'] == i]
        cluster_size = len(cluster_data)
        cluster_percentage = (cluster_size / len(data)) * 100
        
        print(f"\nüìä CLUSTER {i} ({cluster_size} empresas - {cluster_percentage:.1f}% do total):")
        
        # Distribui√ß√£o por pa√≠s
        print("\n   üìç Distribui√ß√£o por Pa√≠s:")
        country_dist = cluster_data['Country'].value_counts(normalize=True) * 100
        for country, percentage in country_dist.items():
            print(f"      ‚Ä¢ {country}: {percentage:.1f}%")
        
        # Distribui√ß√£o por setor
        print("\n   üè≠ Distribui√ß√£o por Setor:")
        sector_dist = cluster_data['S'].value_counts(normalize=True) * 100
        for sector, percentage in sector_dist.items():
            sector_name = sector_names.get(sector, f"Setor {sector}")
            print(f"      ‚Ä¢ {sector_name}: {percentage:.1f}%")
    
    # An√°lise dos centroides dos clusters
    print("\n" + "="*80)
    print("üî¨ CARACTER√çSTICAS MAIS RELEVANTES POR CLUSTER")
    print("="*80)
    
    cluster_centers = pd.DataFrame(
        kmeans.cluster_centers_,
        columns=numeric_cols
    )
    
    for i in range(n_clusters):
        # Ordenando os indicadores pelo valor absoluto do centroide
        sorted_features = cluster_centers.iloc[i].abs().sort_values(ascending=False)
        top_features = sorted_features.head(5)
        
        print(f"\n‚≠ê CLUSTER {i} - Top 5 indicadores com maior influ√™ncia:")
        for feature, value in top_features.items():
            print(f"   ‚Ä¢ {feature}: {value:.4f}")

    
    return data, cluster_centers

# Fun√ß√£o principal
def main():
    print("\n" + "="*80)
    print("üöÄ AN√ÅLISE DE CLUSTERING K-MEANS - EMPRESAS DO GRUPO VISEGRAD (2017-2020)")
    print("="*80)
    
    # Carregando dados
    print("\nüìÇ CARREGANDO DATASETS...")
    data = load_data()
    
    # Pr√©-processamento
    print("\nüîß PR√â-PROCESSANDO OS DADOS...")
    processed_data, numeric_cols = preprocess_data(data)
    
    if processed_data is None:
        print("‚ùå N√£o foi poss√≠vel processar os dados. Verificar os arquivos de entrada.")
        return
    
    # Determinando o n√∫mero ideal de clusters
    print("\nüîç DETERMINANDO O N√öMERO IDEAL DE CLUSTERS...")
    optimal_k, X_scaled = find_optimal_clusters(processed_data, numeric_cols)
    print(f"\n‚úÖ N√∫mero ideal de clusters encontrado: {optimal_k}")
    
    # Realizando o clustering com o n√∫mero ideal de clusters
    print(f"\nüìä APLICANDO K-MEANS COM {optimal_k} CLUSTERS...")
    clustered_data, cluster_centers = perform_clustering(processed_data, numeric_cols, optimal_k, X_scaled)
    
    # Analisando os resultados para diferentes anos
    print("\n" + "="*80)
    print("üìÜ EVOLU√á√ÉO DOS CLUSTERS AO LONGO DOS ANOS")
    print("="*80)
    
    for year in sorted(clustered_data['Year'].unique()):
        year_data = clustered_data[clustered_data['Year'] == year]
        cluster_counts = year_data['Cluster'].value_counts(normalize=True) * 100
        
        print(f"\nüìÖ ANO {year}:")
        for cluster, percentage in cluster_counts.items():
            print(f"   ‚Ä¢ Cluster {cluster}: {percentage:.1f}% das empresas")
    
    # An√°lise de evolu√ß√£o temporal (se existirem m√∫ltiplos anos)
    if len(clustered_data['Year'].unique()) > 1:
        cluster_evolution = pd.crosstab(
            clustered_data['Year'], 
            clustered_data['Cluster'], 
            normalize='index'
        )
        
        plt.figure(figsize=(12, 8))
        cluster_evolution.plot(kind='bar', stacked=True, colormap='viridis')
        plt.title('Evolu√ß√£o da Distribui√ß√£o de Clusters ao Longo dos Anos')
        plt.xlabel('Ano')
        plt.ylabel('Propor√ß√£o')
        plt.legend(title='Cluster')
        plt.grid(True, axis='y')
        plt.tight_layout()
        plt.savefig('cluster_evolution.png')
        plt.close()
    
    print("\n" + "="*80)
    print("‚úÖ AN√ÅLISE DE CLUSTERING CONCLU√çDA COM SUCESSO!")
    print("="*80)
    print("\nArquivos gerados:")
    print("  ‚Ä¢ elbow_method.png - Gr√°fico do m√©todo do cotovelo")
    print("  ‚Ä¢ clusters_pca.png - Visualiza√ß√£o dos clusters usando PCA")
    print("  ‚Ä¢ clusters_by_country.png - Distribui√ß√£o dos dados por pa√≠s")
    print("  ‚Ä¢ clusters_by_sector.png - Distribui√ß√£o dos dados por setor")
    print("  ‚Ä¢ cluster_evolution.png - Evolu√ß√£o dos clusters ao longo do tempo")
    print("="*80)

if __name__ == "__main__":
    main()